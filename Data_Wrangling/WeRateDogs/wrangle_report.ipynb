{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Overview:\n",
    "\n",
    "1. Gather - Gather up the various datasets\n",
    "2. Assess - Assess the quality and issues with the data sets.\n",
    "3. Clean - Tidy up the data sets, removing bad data, combining into a single set.\n",
    "4. Store - Store the cleaned and combined dataset.\n",
    "5. Analyze and Visualize - Analyze the data and support the analysis with good visualizations of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather\n",
    "I started by gathering the various datasets. This went well for the Enhanced Twitter Archive and the Image Predictions, but the instructions for using the twitter API make no mention of the free access having been stopped, or curtailed so much that this step could not be done as laid out. I wasted far too many hours trying to figure it out. I finally went with the alternate method and downloaded the provided additional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess & Clean\n",
    "I assessed the three data sets using both visual inspection and programatic assessment. Through this process I found a number of issues. They, and their resolutions are listed below.\n",
    "\n",
    "### Tidiness\n",
    "1. three data sources\n",
    "2. \"Stage\" data spread across multiple columns\n",
    "\n",
    "Both of these issues were addressed. The seperate data files by joining on the tweet_id field and saving to a master file.\n",
    "\n",
    "The `puppo`, `pupper`, `doggo` and `floofer` columns were merged to a single `stage` column. Then all five columns were dropped as useless busy work, as they were so poorly extracted, and so many tweets actually contain two or more of those, and the \"floofer\" descripter is of a physical characteristic where as the other three relate to the age of the dog. So, should the original wrangle_act.ipynb file be lost, but this one somehow preserved, don't bother with with the \"Stages\", just delete them.\n",
    "\n",
    "### Quality\n",
    "1. Posts w/o photos were removed from the data set.\n",
    "1. Not original posts (replies & retweets) were also removed from the data set.\n",
    "1. `rating_numerator` was changed to a Float and the value was re-extracted from the `text` data\n",
    "1. `name` values extracted poorly turning \"O'Malley\" into \"O\", this was corrected with a one-off replacement.\n",
    "1. \"None\" being used as a `name` - these were changed to \"none\" then delt with in the next step.\n",
    "1. `name` values that are not proper nouns, just words from the post. These values were all dropped from the dataset, replaced with NaN.\n",
    "1. retweets in the image prediction data, these were not merged into the master file, as the retweet records had already been removed from the main data file before the merge, and so the `tweet_id` could not be matched.\n",
    "1. image predictions w/o a dog were dropped from the data set.\n",
    "1. image predictions missing dogs that are there. There was nothing to be done about this issue, in this class. As the data was from a machine learning class and should have / would need to be addressed there. These records were dropped from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store\n",
    "The cleaned data sets were merged into a single set (as mentioned above) and it was saved as `twitter_archive_master.csv` as instructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Visualize\n",
    "I analyzed the data and came up with three insights plus a bonus. I also created four visuals, although, the two pie charts are only marginally useful. The \"Tweets Per Week\" and \"Tweet Love by Tweet Age\" make understanding the data much easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
